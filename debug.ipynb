{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import treebank\n",
    "from nltk.probability import LaplaceProbDist\n",
    "from nltk.tag.hmm import HiddenMarkovModelTrainer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global words_count\n",
    "global tags_count\n",
    "global transition\n",
    "global tags\n",
    "global prob\n",
    "global wt_prob\n",
    "global word_tag\n",
    "global START_STATE\n",
    "global words\n",
    "\n",
    "global TRAIN \n",
    "global INPUT\n",
    "global OUTPUT\n",
    "\n",
    "TRAIN  = './data_tagged.txt'\n",
    "INPUT = './input.txt'\n",
    "OUTPUT = './result.txt'\n",
    "\n",
    "word_tag = {}\n",
    "words_count = {}\n",
    "words = set()\n",
    "tags_count = {}\n",
    "tags = set()\n",
    "transition = {}\n",
    "prob = {}\n",
    "wt_prob = {}\n",
    "START_STATE = 'uwuowo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_probs(distribs):\n",
    "    allowed = ['nn', 'nns', 'prp', 'vb', 'vbz', 'vbp', 'dt', 'vbg', 'jj', 'rb']\n",
    "    rows = set()\n",
    "    cols = set()\n",
    "    for val in distribs.keys():\n",
    "        # temp = val.split(\"|\")\n",
    "        if val[0] in allowed and val[1] in allowed:\n",
    "            rows.add(val[0])\n",
    "            cols.add(val[1])\n",
    "        \n",
    "    rows = list(rows)\n",
    "    cols = list(cols)\n",
    "\n",
    "    df = []\n",
    "    for i in range(len(rows)):\n",
    "        temp = []\n",
    "        for j in range(len(cols)):\n",
    "\n",
    "            temp.append(distribs[(rows[i], cols[j])])\n",
    "            \n",
    "        df.append(temp)\n",
    "        \n",
    "    I = pd.Index(rows, name=\"rows\")\n",
    "    C = pd.Index(cols, name=\"cols\")\n",
    "    df = pd.DataFrame(data=df,index=I, columns=C)\n",
    "    \n",
    "    print(tabulate(df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_emiss(distribs):\n",
    "    allowed = ['nn', 'nns', 'prp', 'vbz', 'vbp', 'dt', 'vbg', 'jj', 'rb']\n",
    "    rows = set()\n",
    "    cols = set()\n",
    "    for val in distribs.keys():\n",
    "        # temp = val.split(\"|\")\n",
    "        if val[1] in allowed:\n",
    "            rows.add(val[0])\n",
    "            cols.add(val[1])\n",
    "        \n",
    "    rows = list(rows)\n",
    "    cols = list(cols)\n",
    "\n",
    "    df = []\n",
    "    for i in range(len(rows)):\n",
    "        temp = []\n",
    "        for j in range(len(cols)):\n",
    "\n",
    "            temp.append(distribs[(rows[i], cols[j])])\n",
    "            \n",
    "        df.append(temp)\n",
    "        \n",
    "    I = pd.Index(rows, name=\"rows\")\n",
    "    C = pd.Index(cols, name=\"cols\")\n",
    "    df = pd.DataFrame(data=df,index=I, columns=C)\n",
    "    \n",
    "    print(tabulate(df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareLib(train):\n",
    "    tagged = []\n",
    "    with open(train, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.lower()\n",
    "            words = line.split()\n",
    "            tmp = []\n",
    "            for word in words:\n",
    "                try:\n",
    "                    word1, word2 = word.split('/')\n",
    "                except ValueError:\n",
    "                    print(line)\n",
    "                tmp.append((word1, word2))\n",
    "            tagged.append(tmp)\n",
    "    f.close()\n",
    "    return tagged\n",
    "\n",
    "def get_words(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.isspace() or not line:\n",
    "                continue\n",
    "            else:\n",
    "                line = line.lower() \n",
    "                build_model(START_STATE + '/' + START_STATE + ' ' + line)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def build_model(line):\n",
    "    wordss = line.split()\n",
    "    # print(words)\n",
    "    for i in range(len(wordss)-1):\n",
    "        current = wordss[i]\n",
    "        nextt = wordss[i+1]\n",
    "        # print(current, nextt)\n",
    "        word1, tag1 = current.split('/')\n",
    "        word2, tag2 = nextt.split('/')\n",
    "        '''\n",
    "        count the number of words\n",
    "        '''\n",
    "        if word1 != START_STATE:\n",
    "            if word1 not in words_count:\n",
    "                words_count[word1] = 1\n",
    "            else:\n",
    "                words_count[word1] += 1\n",
    "            words.add(word1)\n",
    "        if word2 not in words_count:\n",
    "            words_count[word2] = 1\n",
    "        else:\n",
    "            words_count[word2] += 1\n",
    "        words.add(word2)\n",
    "        '''\n",
    "        count the number of tags\n",
    "        '''\n",
    "        if tag1 not in tags_count:\n",
    "            tags_count[tag1] = 1\n",
    "        else:\n",
    "            tags_count[tag1] += 1\n",
    "        if tag2 not in tags_count:\n",
    "            tags_count[tag2] = 1\n",
    "        else:\n",
    "            tags_count[tag2] += 1\n",
    "        '''\n",
    "        count the number of transitions\n",
    "        '''\n",
    "        tag_pair = (tag1, tag2)\n",
    "        if tag_pair not in transition:\n",
    "            transition[tag_pair] = 1\n",
    "        else:\n",
    "            transition[tag_pair] += 1\n",
    "        tags.add(tag1)\n",
    "        tags.add(tag2)\n",
    "        '''\n",
    "        count the number of word having tag\n",
    "        '''\n",
    "        if word1 != START_STATE:\n",
    "            if (word1, tag1) not in word_tag:\n",
    "                word_tag[(word1, tag1)] = 1\n",
    "            else:\n",
    "                word_tag[(word1, tag1)] += 1\n",
    "        if (word2, tag2) not in word_tag:\n",
    "            word_tag[(word2, tag2)] = 1\n",
    "        else:\n",
    "            word_tag[(word2, tag2)] += 1\n",
    "\n",
    "def calculateTransitionProbability():\n",
    "    for pair in transition:\n",
    "        tag1 = pair[0]\n",
    "        count = 0\n",
    "        for pair2 in transition:\n",
    "            if pair2[0] == tag1:\n",
    "                count+= transition[pair2]\n",
    "        prob[pair] = (transition[pair] + 1)/ (count + len(tags))  #add laplace smoothing\n",
    "    return prob\n",
    "\n",
    "def transitionSmoothing():\n",
    "    prob = calculateTransitionProbability()\n",
    "    a = {}\n",
    "    for pair in transition:\n",
    "        if pair[0] in a:\n",
    "            a[pair[0]] += transition[pair]\n",
    "        else:\n",
    "            a[pair[0]] = transition[pair]\n",
    "    for tag in tags:\n",
    "        if tag not in a.keys():\n",
    "            a[tag] = 0\n",
    "    for tag in tags:\n",
    "        if (START_STATE, tag) not in prob:\n",
    "            prob[(START_STATE, tag)] = 1 / (a[START_STATE] + len(tags))\n",
    "    for tag1 in tags:\n",
    "        for tag2 in tags:\n",
    "            if (tag1, tag2) not in prob:\n",
    "                prob[(tag1, tag2)] = (1) / (a[tag1] + len(tags))\n",
    "    # pretty_print_probs(prob)\n",
    "    return prob\n",
    "\n",
    "def calculateWordTagProbability():\n",
    "    for word in words_count:\n",
    "        for tag in tags:\n",
    "            count = 0\n",
    "            if (word, tag) in word_tag:\n",
    "                count = word_tag[(word, tag)]\n",
    "            tmp = (count+1)/(tags_count[tag] + len(words))\n",
    "            wt_prob[(word, tag)] = tmp\n",
    "    # pretty_print_emiss(wt_prob)\n",
    "    return wt_prob\n",
    "\n",
    "def viterbi(sentence, tags, prob, wt_prob, tag_count_emis, words):\n",
    "    # print(prob)\n",
    "    word_list = sentence.split()\n",
    "    current_prob = {}\n",
    "    for tag in tags:\n",
    "        tp = 0\n",
    "        em = 0\n",
    "        if (START_STATE, tag) in prob:\n",
    "            tp = (prob[START_STATE, tag])\n",
    "        if word_list[0].lower() in words:\n",
    "            if (word_list[0].lower(), tag) in wt_prob:\n",
    "                em = (wt_prob[(word_list[0].lower(), tag)])\n",
    "                current_prob[tag] = tp * em\n",
    "        else:\n",
    "            em = 1 / (tag_count_emis[tag] + len(words))\n",
    "            current_prob[tag] = tp\n",
    "    if len(word_list) == 1:\n",
    "        max_path = max(current_prob, key=current_prob.get)\n",
    "        return max_path\n",
    "    else:\n",
    "        for i in range(1, len(word_list)):\n",
    "            previous_prob = current_prob\n",
    "            current_prob = {}\n",
    "            locals()['dict{}'.format(i)] = {}\n",
    "            previous_tag = \"uwuowo\"\n",
    "            for tag in tags:\n",
    "                if word_list[i].lower() in words:\n",
    "                    if (word_list[i].lower(), tag) in wt_prob:\n",
    "                        em = (wt_prob[(word_list[i].lower(), tag)])\n",
    "                        max_prob, previous_state = max((previous_prob[previous_tag] * \n",
    "                            prob[(previous_tag, tag)] * em, previous_tag) for previous_tag in\n",
    "                                                       previous_prob)\n",
    "                        current_prob[tag] = max_prob\n",
    "                        locals()['dict{}'.format(i)][(previous_state, tag)] = max_prob\n",
    "                        previous_tag = previous_state\n",
    "                else:\n",
    "                    # print(word_list[i])\n",
    "                    em = (1) / (tag_count_emis[tag] + len(words))\n",
    "                    try:\n",
    "                        max_prob, previous_state = max((previous_prob[previous_tag] * prob[(previous_tag, tag)] * em, previous_tag) for previous_tag in previous_prob)\n",
    "                    except TypeError:\n",
    "                        print('ERROR')\n",
    "                        # print(previous_prob[previous_tag])\n",
    "                        # print((previous_tag, tag))\n",
    "                        # print(prob)\n",
    "                    current_prob[tag] = max_prob\n",
    "                    locals()['dict{}'.format(i)][(previous_state, tag)] = max_prob\n",
    "                    previous_tag = previous_state\n",
    "            # print(max_prob)\n",
    "            if i == len(word_list) - 1:\n",
    "                max_path = \"\"\n",
    "                last_tag = max(current_prob, key=current_prob.get)\n",
    "                max_path = max_path + last_tag\n",
    "                for j in range(len(word_list) - 1, 0, -1):\n",
    "                    for key in locals()['dict{}'.format(j)]:\n",
    "                        data1, data2 = key\n",
    "                        if data2 == previous_tag:\n",
    "                            max_path = max_path + \" \" + data1\n",
    "                            previous_tag = data1\n",
    "                            break\n",
    "                result = max_path.split()\n",
    "                result.reverse()\n",
    "                return \" \".join(result)\n",
    "\n",
    "def writeOutput(init, result, accs, lib_res, lib_acc, file):\n",
    "    # count = -1\n",
    "    with open(file, 'a', encoding='utf-8') as f:\n",
    "        for i in range(len(result)):\n",
    "            f.write('init: {}'.format(init[i].lower()))\n",
    "            f.write('mine: {}'.format(result[i]))\n",
    "            f.write('\\n')\n",
    "            f.write(str(accs[i]))\n",
    "            f.write('\\n')\n",
    "            f.write('lib: {}'.format(lib_res[i]))\n",
    "            f.write('\\n')\n",
    "            f.write(str(lib_acc[i]))\n",
    "            f.write('\\n')\n",
    "            f.write('\\n')\n",
    "    f.close()\n",
    "    print(str(sum(accs)/len(accs)))\n",
    "    print(str(sum(lib_acc)/len(lib_acc)))\n",
    "\n",
    "\n",
    "def runWithLib():\n",
    "    tagged = prepareLib(TRAIN)\n",
    "    print(tagged)\n",
    "    trainer = HiddenMarkovModelTrainer()\n",
    "    tagger = trainer.train_supervised(tagged, estimator=LaplaceProbDist)\n",
    "    result = []\n",
    "    accs = []\n",
    "    with open('./input.txt', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line, gt = splitAndReconstruct(line)\n",
    "            pos = tagger.tag(line.split())\n",
    "            string = \"\"\n",
    "            pred = []\n",
    "            for pair in pos:\n",
    "                string = string+pair[0] + '/' + pair[1] + \" \"\n",
    "                pred.append(pair[1])\n",
    "            result.append(string)\n",
    "            accs.append(accuracy_score(gt, pred))\n",
    "            # print('\\n')\n",
    "    f.close()\n",
    "    # writeOutput(result, accs, OUTPUT)\n",
    "    return result, accs\n",
    "            \n",
    "def splitAndReconstruct(sentence):\n",
    "    f = \"\"\n",
    "    tags = []\n",
    "    words_and_tags = sentence.split()\n",
    "    for pair in words_and_tags:\n",
    "        try:\n",
    "            word, tag = pair.split('/')\n",
    "        except ValueError:\n",
    "            print(sentence)\n",
    "        if f != \"\":\n",
    "            f = f+' '\n",
    "        f = f+word.lower()\n",
    "        tags.append(tag.lower())\n",
    "    return f, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. demo with test data (label available)\n",
      "2. demo with a random single sentence\n",
      "1\n",
      "[[('now', 'rb'), ('i', 'prp'), ('am', 'vbp'), ('senior', 'jj'), ('engineer', 'nn'), ('at', 'in'), ('twitter', 'nnp')], [('i', 'prp'), ('had', 'vbd'), ('an', 'dt'), ('interview', 'nn'), ('with', 'in'), ('scribd', 'nnp'), (',', ','), ('who', 'wp'), ('i', 'prp'), ('really', 'rb'), ('liked', 'vbd'), ('at', 'in'), ('the', 'dt'), ('time', 'nn')], [('you', 'prp'), ('can’t', 'md'), ('invert', 'vb'), ('a', 'dt'), ('binary', 'jj'), ('tree', 'nn'), ('on', 'in'), ('a', 'dt'), ('whiteboard', 'nn')], [('i', 'prp'), ('interviewed', 'vbd'), ('at', 'in'), ('mozilla', 'nnp'), ('in', 'in'), ('2008', 'nn')], [('because', 'cc'), ('i', 'prp'), (\"didn't\", 'md'), ('have', 'vb'), ('an', 'dt'), ('undergraduate', 'jj'), ('degree', 'nn')], [('i', 'prp'), ('wanted', 'vbd'), ('to', 'to'), ('be', 'vb'), ('a', 'dt'), ('professional', 'jj'), ('football', 'nn'), ('player', 'nn'), ('but', 'cc'), ('the', 'dt'), ('new', 'nn'), ('york', 'nn'), ('jets', 'nn'), (\"didn't\", 'md'), ('want', 'vb'), ('me', 'nn'), ('because', 'cc'), ('i', 'prp'), (\"couldn't\", 'md'), ('run', 'vb'), ('a', 'dt'), ('sub-4.3', 'jj'), ('second', 'nn'), ('40', 'jj'), ('yard', 'nn'), ('dash', 'nn')], [('never', 'rb'), ('let', 'vb'), ('anyone', 'nn'), ('tell', 'vb'), ('you', 'prp'), ('that', 'wdt'), ('you', 'prp'), ('are', 'vbp'), ('not', 'rb'), ('worthy', 'jj')], [('they', 'prp'), ('asked', 'vbd'), ('me', 'nn'), ('a', 'dt'), ('question', 'nn'), ('that', 'wdt'), ('took', 'vbd'), ('me', 'nn'), ('a', 'dt'), ('bit', 'nn'), ('of', 'in'), ('time', 'nn'), ('to', 'to'), ('answer', 'nn'), (',', ','), ('and', 'cc'), ('the', 'dt'), ('interviewer', 'nn'), ('cut', 'vb'), ('me', 'nn'), ('off', 'rp'), ('in', 'in'), ('the', 'dt'), ('middle', 'nn')], [('i', 'prp'), ('was', 'vbd'), ('rejected', 'vbd'), ('from', 'cc'), ('countless', 'jj'), ('internships', 'nns'), ('and', 'cc'), ('junior', 'jj'), ('positions', 'nns'), ('at', 'in'), ('agencies', 'nns')], [('one', 'cd'), ('month', 'nn'), ('later', 'rb'), (',', ','), ('i', 'prp'), ('got', 'vbd'), ('an', 'dt'), ('offer', 'nn'), ('from', 'cc'), ('slack', 'nn')], [('set', 'vb'), ('up', 'rp'), ('an', 'dt'), ('organization', 'nn'), ('to', 'to'), ('improve', 'vb'), ('the', 'dt'), ('way', 'nn'), ('your', 'prp$'), ('team', 'nn'), ('works', 'vbz'), ('together', 'nn')], [('the', 'dt'), ('feed', 'nn'), ('shows', 'vbz'), ('you', 'prp'), ('events', 'nns'), ('from', 'in'), ('people', 'nns'), ('you', 'prp'), ('follow', 'vb'), ('and', 'cc'), ('repositories', 'nns'), ('you', 'prp'), ('watch', 'vb')], [('accommodation', 'nn'), ('letters', 'nn'), ('are', 'vbp'), ('issued', 'vbn'), ('for', 'cc'), ('the', 'dt'), ('entire', 'rb'), ('academic', 'jj'), ('year', 'nn')], [('voting', 'vbg'), ('is', 'vbz'), ('a', 'dt'), ('general', 'jj'), ('technique', 'nn'), ('where', 'wrb'), ('we', 'prp'), ('let', 'vb'), ('the', 'dt'), ('features', 'nns'), ('vote', 'vb'), ('for', 'cc'), ('all', 'pdt'), ('models', 'nns'), ('that', 'wdt'), ('are', 'vbp'), ('compatible', 'jj'), ('with', 'in'), ('it', 'nn')], [('ransac', 'nnp'), ('divides', 'vbz'), ('data', 'nn'), ('into', 'in'), ('inliers', 'nns'), ('and', 'cc'), ('outliers', 'ns'), ('and', 'cc'), ('yields', 'vbz'), ('estimate', 'jj'), ('computed', 'vbn'), ('from', 'cc'), ('minimal', 'jj'), ('set', 'nn'), ('of', 'in'), ('inliers', 'nns')], [('byu', 'nnp'), ('may', 'md'), ('be', 'vbp'), ('one', 'cd'), ('of', 'in'), ('only', 'dt'), ('campuses', 'nns'), ('in', 'in'), ('the', 'dt'), ('nation', 'nn'), ('where', 'rb'), ('you', 'prp'), ('have', 'vb'), ('genuine', 'jj'), ('diversity', 'nn'), ('.', '.')], [('you', 'prp'), ('can', 'md'), ('hear', 'vb'), ('mitt', 'nnp'), ('romney', 'nnp'), ('and', 'cc'), ('harry', 'nnp'), ('reid', 'nnp'), ('and', 'cc'), ('no', 'dt'), ('one', ''), ('is', 'vbz'), ('throwing', 'vbg'), ('pies', 'nns'), ('and', 'cc'), ('protesting', 'vbg'), ('that', 'wdt'), ('the', 'dt'), ('speaker', 'nn'), (\"doesn't\", 'md'), ('meet', 'vb'), ('their', 'prp$'), ('ideological', 'jj'), ('litmus', 'nn'), ('test', 'nn'), ('.', '.')], [('it', 'prp'), ('depends', 'vbz'), ('on', 'in'), ('who', 'wp'), ('you', 'prp'), ('are', 'vbp'), ('and', 'cc'), ('what', 'wp'), ('you', 'prp'), ('want', 'vb'), ('from', 'rp'), ('your', 'prp$'), ('university', 'nn'), ('experience', 'nn'), ('.', '.')], [('i', 'prp'), ('enjoyed', 'vbd'), ('my', 'prp$'), ('time', 'nn'), ('there', 'rp')], [('if', 'in'), ('you', 'prp'), ('think', 'vb'), ('of', 'in'), ('college', 'nn'), ('as', 'in'), ('an', 'dt'), ('opportunity', 'nn'), ('for', 'cc'), ('drunken', 'jj'), ('orgies', 'nns'), (',', ','), ('you', 'prp'), ('are', 'vbp'), ('going', 'vbg'), ('to', 'to'), ('hate', 'vb'), ('byu', 'nnp'), ('.', '.')], [('if', 'in'), ('you', 'prp'), ('like', 'vb'), ('the', 'dt'), ('idea', 'nn'), ('of', 'in'), ('attending', 'vbg'), ('a', 'dt'), ('school', 'nn'), ('where', 'wp'), ('values', 'nns'), ('and', 'cc'), ('ideals', 'nns'), ('and', 'cc'), ('commitment', 'nn'), ('to', 'to'), ('clean', 'jj'), ('living', 'nn'), ('is', 'vbz'), ('the', 'dt'), ('norm', 'nn'), (',', ','), ('then', 'rb'), ('you', 'prp'), ('might', 'md'), ('enjoy', 'vb'), ('byu', 'nnp')], [('byu', 'nnp'), ('has', 'vbz'), ('very', 'rb'), ('little', 'jj'), ('in', 'in'), ('the', 'dt'), ('way', 'nn'), ('of', 'in'), ('political', 'jj'), ('or', 'cc'), ('racial', 'jj'), ('diversity', 'nn')], [('if', 'in'), ('you', 'prp'), ('are', 'vbp'), ('lds', 'nnp'), (',', ','), ('or', 'cc'), ('come', 'vb'), ('from', 'rp'), ('a', 'dt'), ('conservative', 'jj'), ('background', 'nn'), (',', ','), ('chances', 'nns'), ('are', 'vbp'), ('you', 'prp'), ('will', 'md'), ('have', 'vb'), ('a', 'dt'), ('very', 'rb'), ('positive', 'jj'), ('experience', 'nn'), ('at', 'in'), ('byu', 'nnp')], [('it', 'prp'), ('has', 'vbz'), ('the', 'dt'), ('best', 'rbs'), ('library', 'nn'), ('i', 'prp'), ('have', 'vbp'), ('ever', 'rb'), ('visited', 'vbg'), ('and', 'cc'), ('it', 'prp'), ('is', 'vbz'), ('true', 'jj'), ('that', 'wdt'), ('the', 'dt'), ('campus', 'nn'), ('is', 'vbz'), ('very', 'rb'), ('beautiful', 'jj')], [('the', 'dt'), ('professors', 'nns'), ('are', 'vbp'), ('excellent', 'jj')], [('universities', 'nns'), ('determine', 'vb'), ('their', 'prp$'), ('overall', 'jj'), ('operating', 'jj'), ('costs', 'nns'), ('including', 'vbg'), ('professor', 'nn'), ('salaries', 'nns'), (',', ','), ('campus', 'nn'), ('maintenance', 'nn'), ('and', 'cc'), ('cost', 'nn'), ('of', 'in'), ('supplies', 'nns'), ('.', '.')], [('this', 'pdt'), ('makes', 'vbz'), ('tuition', 'nn'), ('costs', 'nnp'), ('for', 'cc'), ('students', 'nns'), ('incredibly', 'rb'), ('low', 'jj'), (',', ','), ('and', 'cc'), ('norris', 'nnp'), ('said', 'vbd'), ('it', 'prp'), ('also', 'rb'), ('encourages', 'vbz'), ('students', 'nns'), ('to', 'to'), ('apply', 'vb'), ('to', 'to'), ('the', 'dt'), ('university', 'nn'), ('.', '.')], [('because', 'cc'), ('tuition', 'nn'), ('is', 'vbz'), ('so', 'rb'), ('affordable', 'jj'), (',', ','), ('some', 'dt'), ('students', 'nns'), ('are', 'vbp'), ('able', 'jj'), ('to', 'to'), ('work', 'vb'), ('summer', 'nn'), ('jobs', 'nns'), ('to', 'to'), ('help', 'vb'), ('pay', 'vb'), ('for', 'cc'), ('the', 'dt'), ('next', 'in'), ('year’s', 'prp$'), ('tuition', 'nn'), ('.', '.')], [('byu', 'nnp'), ('tuition', 'nn'), ('is', 'vbz'), ('very', 'rb'), ('reasonable', 'jj'), ('and', 'cc'), ('cheaper', 'jjr'), ('than', 'in'), ('any', 'dt'), ('other', 'jj'), ('place', 'nn'), ('i', 'prp'), ('was', 'vbd'), ('considering', 'vbg'), ('.', '.')], [('they', 'prp'), ('also', 'rb'), ('appreciate', 'vb'), ('students', 'nns'), ('having', 'vbg'), ('experience', 'nn'), ('beyond', 'in'), ('just', 'dt'), ('academics', 'nns'), ('.', '.')], [('people', 'nns'), ('who', 'wp'), ('are', 'vbp'), ('caught', 'vbn'), ('breaking', 'vbg'), ('the', 'dt'), ('honor', 'nn'), ('code', 'nn'), ('are', 'vbp'), ('dismissed', 'vbn'), ('.', '.')], [('i', 'prp'), ('was', 'vbd'), ('happy', 'jj'), ('to', 'to'), ('embrace', 'vb'), ('the', 'dt'), ('safety', 'nn'), ('i', 'prp'), ('felt', 'vbd'), ('at', 'in'), ('the', 'dt'), ('y', 'nnp'), ('.', '.')], [('byu', 'nnp'), ('may', 'dt'), ('be', 'vbp'), ('one', 'cd'), ('of', 'in'), ('only', 'dt'), ('campuses', 'nns'), ('in', 'in'), ('the', 'dt'), ('nation', 'nn'), ('where', 'rb'), ('you', 'prp'), ('have', 'vb'), ('genuine', 'jj'), ('diversity', 'nn'), ('.', '.')], [('you', 'prp'), ('can', 'md'), ('hear', 'vb'), ('mitt', 'nnp'), ('romney', 'nnp'), ('and', 'cc'), ('harry', 'nnp'), ('reid', 'nnp'), ('and', 'cc'), ('no', 'dt'), ('one', ''), ('is', 'vbz'), ('throwing', 'vbg'), ('pies', 'nns'), ('and', 'cc'), ('protesting', 'vbg'), ('that', 'wdt'), ('the', 'dt'), ('speaker', 'nn'), (\"doesn't\", 'md'), ('meet', 'vb'), ('their', 'prp$'), ('ideological', 'jj'), ('litmus', 'nn'), ('test', 'nn'), ('.', '.')], [('it', 'prp'), ('depends', 'vbz'), ('on', 'in'), ('who', 'wp'), ('you', 'prp'), ('are', 'vbp'), ('and', 'cc'), ('what', 'wp'), ('you', 'prp'), ('want', 'vb'), ('from', 'rp'), ('your', 'prp$'), ('university', 'nn'), ('experience', 'nn'), ('.', '.')], [('if', 'in'), ('you', 'prp'), ('like', 'vb'), ('the', 'dt'), ('idea', 'nn'), ('of', 'in'), ('attending', 'vbg'), ('a', 'dt'), ('school', 'nn'), ('where', 'wp'), ('values', 'nns'), ('and', 'cc'), ('ideals', 'nns'), ('and', 'cc'), ('commitment', 'nn'), ('to', 'to'), ('clean', 'jj'), ('living', 'nn'), ('is', 'vbz'), ('the', 'dt'), ('norm', 'nn,'), ('then', 'rb'), ('you', 'prp'), ('might', 'md'), ('enjoy', 'vb'), ('byu', 'nnp')], [('byu', 'nnp'), ('has', 'vbz'), ('very', 'rb'), ('little', 'jj'), ('in', 'in'), ('the', 'dt'), ('way', 'nn'), ('of', 'in'), ('political', 'jj'), ('or', 'cc'), ('racial', 'jj'), ('diversity', 'nn')], [('if', 'in'), ('you', 'prp'), ('are', 'vbp'), ('lds', 'nnp'), (',', ','), ('or', 'cc'), ('come', 'vb'), ('from', 'rp'), ('a', 'dt'), ('conservative', 'jj'), ('background', 'nn,'), ('chances', 'nns'), ('are', 'vbp'), ('you', 'prp'), ('will', 'md'), ('have', 'vb'), ('a', 'dt'), ('very', 'rb'), ('positive', 'jj'), ('experience', 'nn'), ('at', 'in'), ('byu', 'nnp')], [('it', 'prp'), ('has', 'vbz'), ('the', 'dt'), ('best', 'rbs'), ('library', 'nn'), ('i', 'prp'), ('have', 'vbp'), ('ever', 'rb'), ('visited', 'vbg'), ('and', 'cc'), ('it', 'prp'), ('is', 'vbz'), ('true', 'jj'), ('that', 'wdt'), ('the', 'dt'), ('campus', 'nn'), ('is', 'vbz'), ('very', 'rb'), ('beautiful', 'jj')], [('the', 'dt'), ('professors', 'nns'), ('are', 'vbp'), ('excellent', 'jj')], [('universities', 'nns'), ('determine', 'vb'), ('their', 'prp$'), ('overall', 'jj'), ('operating', 'jj'), ('costs', 'nns'), ('including', 'vbg'), ('professor', 'nn'), ('salaries', 'nns'), (',', ','), ('campus', 'nn'), ('maintenance', 'nn'), ('and', 'cc'), ('cost', 'nn'), ('of', 'in'), ('supplies', 'nns'), ('.', '.')], [('this', 'pdt'), ('makes', 'vbz'), ('tuition', 'nn'), ('costs', 'nnp'), ('for', 'cc'), ('students', 'nns'), ('incredibly', 'rb'), ('low', 'jj'), (',', ','), ('and', 'cc'), ('norris', 'nnp'), ('said', 'vbd'), ('it', 'prp'), ('also', 'rb'), ('encourages', 'vbz'), ('students', 'nns'), ('to', 'to'), ('apply', 'vb'), ('to', 'to'), ('the', 'dt'), ('university', 'nn'), ('.', '.')], [('because', 'cc'), ('tuition', 'nn'), ('is', 'vbz'), ('so', 'rb'), ('affordable', 'jj'), (',', ','), ('some', 'dt'), ('students', 'nns'), ('are', 'vbp'), ('able', 'jj'), ('to', 'to'), ('work', 'vb'), ('summer', 'nn'), ('jobs', 'nns'), ('to', 'to'), ('help', 'vb'), ('pay', 'vb'), ('for', 'cc'), ('the', 'dt'), ('next', 'in'), ('year’s', 'prp$'), ('tuition', 'nn'), ('.', '.')], [('byu', 'nnp'), ('tuition', 'nn'), ('is', 'vbz'), ('very', 'rb'), ('reasonable', 'jj'), ('and', 'cc'), ('cheaper', 'jjr'), ('than', 'in'), ('any', 'dt'), ('other', 'jj'), ('place', 'nn'), ('i', 'prp'), ('was', 'vbd'), ('considering', 'vbg')], [('byu', 'nnp'), ('still', 'rb'), ('manages', 'vbz'), ('to', 'to'), ('operate', 'vb'), ('a', 'dt'), ('professional', 'jj'), ('and', 'cc'), ('reputable', 'jj'), ('university', 'nn'), ('.', '.')], [('you', 'prp'), ('are', 'vbp'), ('often', 'rb'), ('judged', 'vbn'), ('quickly', 'rb'), ('and', 'cc'), ('harshly', 'rb'), ('in', 'in'), ('this', 'pdt'), ('world', 'nn'), (',', ','), ('always', 'rb'), ('insure', 'vb'), ('that', 'dt'), ('you', 'prp'), ('put', 'vb'), ('the', 'dt'), ('best', 'jjs'), ('possible', 'jj'), ('words', 'nns'), ('into', 'in'), ('print', 'nn'), ('.', '.')], [('i', 'prp'), ('would', 'md'), ('suggest', 'vb'), ('two', 'cd'), ('approaches', 'nns')], [('they', 'prp'), ('also', 'rb'), ('appreciate', 'vb'), ('students', 'nns'), ('having', 'vbg'), ('experience', 'nn'), ('beyond', 'in'), ('just', 'dt'), ('academics', 'nns'), ('.', '.')], [('people', 'nns'), ('who', 'wp'), ('are', 'vbp'), ('caught', 'vbn'), ('breaking', 'vbg'), ('the', 'dt'), ('honor', 'nn'), ('code', 'nn'), ('are', 'vbp'), ('dismissed', 'vbn')], [('i', 'prp'), ('was', 'vbd'), ('happy', 'jj'), ('to', 'to'), ('embrace', 'vb'), ('the', 'dt'), ('safety', 'nn'), ('i', 'prp'), ('felt', 'vbd'), ('at', 'in'), ('the', 'dt'), ('y', 'nnp')], [('the', 'dt'), ('campus', 'nn'), ('has', 'vbz'), ('numerous', 'jj'), ('organizations', 'nns'), ('staffed', 'vbd'), ('by', 'in'), ('and', 'cc'), ('focused', 'vbd'), ('on', 'in'), ('international', 'jj'), ('students', 'nns')], [('some', 'dt'), ('jobs', 'nns'), ('are', 'vbp'), ('available', 'jj'), ('and', 'cc'), ('internships', 'nns'), ('are', 'vbp'), ('available', 'jj'), ('through', 'in'), ('broad', 'jj'), ('avenues', 'nns')], [('residing', 'vbg'), ('within', 'in'), ('the', 'dt'), ('university', 'nn'), ('campus', 'nn'), ('can', 'md'), ('also', 'rb'), ('help', 'vb'), ('you', 'prp'), ('navigate', 'vb'), ('easily', 'rb')], [('if', 'in'), ('you', 'prp'), ('like', 'vb'), ('football', 'nn'), (',', ','), ('we', 'prp'), ('have', 'vb'), ('a', 'dt'), ('good', 'jj'), ('team', 'nn'), (',', ','), ('a', 'dt'), ('nice', 'jj'), ('stadium', 'nn'), (',', ','), ('and', 'cc'), ('the', 'dt'), ('tailgating', 'vbg'), ('is', 'vbz'), ('always', 'rb'), ('fun', 'jj'), ('.', '.')], [('i', 'prp'), ('have', 'vbp'), ('never', 'rb'), ('felt', 'vbd'), ('in', 'in'), ('danger', 'nn'), ('and', 'cc'), ('people', 'nns'), ('are', 'vbp'), ('very', 'rb'), ('friendly', 'jj'), ('here', 'rb')], [('i', 'prp'), ('have', 'vbp'), ('lived', 'vbd'), ('on', 'in'), ('campus', 'nn'), ('in', 'in'), ('a', 'dt'), ('large', 'jj'), ('cluster', 'nn'), ('at', 'in'), ('lassonde', 'nnp'), ('studios', 'nnp'), ('.', '.')], [('i', 'prp'), ('haven’t', 'vbp'), ('had', 'vbd'), ('a', 'dt'), ('problem', 'nn'), ('getting', 'vbg'), ('interviews', 'nns'), ('despite', 'in'), ('my', 'prp$'), ('lack', 'nn'), ('of', 'in'), ('internships', 'nns')], [('microsoft', 'nnp'), ('and', 'cc'), ('amazon', 'nnp'), ('are', 'vbp'), ('regular', 'jj'), ('attendees', 'nns'), ('at', 'in'), ('our', 'prp$'), ('stem', 'nnp'), ('career', 'nn'), ('fair', 'nn'), (',', ','), ('and', 'cc'), ('facebook', 'nnp'), ('has', 'vbz'), ('also', 'rb'), ('attended', 'vbd'), ('.', '.')], [('he', 'prp'), ('has', 'vbz'), ('entered', 'vbd'), ('in', 'in'), ('a', 'dt'), ('restaurant', 'nn'), ('.', '.')], [('the', 'dt'), ('baby', 'nn'), ('has', 'vbz'), ('broken', 'vbn'), ('the', 'dt'), ('glass', 'nn'), ('.', '.')], [('i', 'prp'), ('have', 'vb'), ('put', 'vb'), ('the', 'dt'), ('money', 'nn'), ('on', 'in'), ('the', 'dt'), ('table', 'nn'), ('.', '.')], [('my', 'prp$'), ('sister', 'nn'), ('has', 'vbz'), ('already', 'rb'), ('made', 'vbd'), ('a', 'dt'), ('big', 'jj'), ('cake', 'nn')], [('you', 'prp'), ('have', 'vb'), ('grown', 'vbd'), ('since', 'rb'), ('the', 'dt'), ('last', 'jj'), ('time', 'nn'), ('i', 'prp'), ('saw', 'vbd'), ('you', 'prp')]]\n",
      "0.6304310099448192\n",
      "0.5316461787666645\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    get_words('./data_tagged.txt')\n",
    "    # print(transition.items())\n",
    "    prob = transitionSmoothing()\n",
    "    wt_prob = calculateWordTagProbability()\n",
    "    tag_count_emis = {}\n",
    "    for probb in wt_prob.items():\n",
    "        key_tag = probb[0]\n",
    "        # print(key_tag)\n",
    "        val = key_tag[-1]\n",
    "        if val in tag_count_emis:\n",
    "            tag_count_emis[val] += 1\n",
    "        else:\n",
    "            tag_count_emis[val] = 1\n",
    "    \n",
    "    print('1. demo with test data (label available)')\n",
    "    print('2. demo with a random single sentence')\n",
    "    k = int(input())\n",
    "    if k == 1:\n",
    "        init = []\n",
    "        result = []\n",
    "        accs = []\n",
    "        with open('./input.txt', 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                init.append(line)\n",
    "                line, gt = splitAndReconstruct(line)\n",
    "                path = viterbi(line, tags, prob, wt_prob, tag_count_emis, words)\n",
    "                tmp = line.split()\n",
    "                ptmp = path.split()\n",
    "                string = \"\"\n",
    "                for i in range(len(tmp)):\n",
    "                    string += tmp[i] + '/' + ptmp[i] + ' '\n",
    "                result.append(string)\n",
    "                acc = accuracy_score(gt, ptmp)\n",
    "                # print('gt: {}'.format(gt))\n",
    "                # print('pred: {}'.format(ptmp))\n",
    "                accs.append(acc)\n",
    "        f.close()\n",
    "        lib_res, lib_acc = runWithLib()\n",
    "        writeOutput(init, result, accs, lib_res, lib_acc, OUTPUT)\n",
    "    else:\n",
    "        sent = input()\n",
    "        sent = sent.lower()\n",
    "        path = viterbi(sent, tags, prob, wt_prob, tag_count_emis, words)\n",
    "        tmp = sent.split()\n",
    "        ptmp = path.split()\n",
    "        string = \"\"\n",
    "        for i in range(len(tmp)):\n",
    "            if string != \"\":\n",
    "                string = string + ' '\n",
    "            string += tmp[i] + '/' + ptmp[i]\n",
    "        print(string)\n",
    "    # print('\\n')\n",
    "    \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
